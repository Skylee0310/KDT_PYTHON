{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증\n",
    "- 부족한 데이터 셋 및 특정 데이터에 과대적합되는 문제를 해결하기 위한 방안.\n",
    "- 학습 데이터셋을 일정 크기의 데이터로 n개 분리 후 1/n은 검증용, 나머지는 학습용으로 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold 인스턴스 생성 => 데이터를 2개로 분할해주는 객체\n",
    "k_fold = KFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2, 3]), array([0, 1]))\n",
      "(array([0, 1]), array([2, 3]))\n",
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "dtas = k_fold.split(X, y) # 그래서 generator가 뭔데..>?\n",
    "for dta in dtas:\n",
    "    print(dta)\n",
    "\n",
    "\n",
    "dtas = k_fold.split(X) \n",
    "for trn, tst in dtas:\n",
    "    print(trn, tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Weight  56 non-null     float64\n",
      " 1   Length  56 non-null     float64\n",
      " 2   Height  56 non-null     float64\n",
      " 3   Width   56 non-null     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.9 KB\n"
     ]
    }
   ],
   "source": [
    "## perch.csv 파일 데이터 기본 5등분\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "perchDF = pd.read_csv('../data/perch3.csv')\n",
    "perchDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (37,) (19,)\n",
      "1 => (37,) (19,)\n",
      "2 => (38,) (18,)\n"
     ]
    }
   ],
   "source": [
    "# perchDF = > 5등분\n",
    "fold_5 = KFold(n_splits=3)\n",
    "datasets = fold_5.split(perchDF)\n",
    "\n",
    "for idx, (trn, tst) in enumerate(datasets) :\n",
    "    print(f'{idx} => {trn.shape} {tst.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] => [ 0  1  2  3  4  5  6  8  9 10 12 14 15 16 17 18 19 21 22 23 24 25 28 29\n",
      " 30 31 32 33 36 37 38 39 40 41 42 45 47 49 50 51 52 53 54 55] [ 7 11 13 20 26 27 34 35 43 44 46 48]\n",
      "\n",
      "[1] => [ 0  1  2  3  4  7  8  9 10 11 12 13 14 15 16 18 20 21 22 23 24 25 26 27\n",
      " 28 30 31 32 34 35 36 37 38 39 40 41 43 44 46 47 48 50 51 53 55] [ 5  6 17 19 29 33 42 45 49 52 54]\n",
      "\n",
      "[2] => [ 1  2  3  4  5  6  7  9 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 31 32 33 34 35 36 38 39 40 42 43 44 45 46 48 49 52 53 54] [ 0  8 10 15 30 37 41 47 50 51 55]\n",
      "\n",
      "[3] => [ 0  1  2  5  6  7  8  9 10 11 12 13 14 15 17 19 20 21 23 25 26 27 29 30\n",
      " 31 33 34 35 37 39 40 41 42 43 44 45 46 47 48 49 50 51 52 54 55] [ 3  4 16 18 22 24 28 32 36 38 53]\n",
      "\n",
      "[4] => [ 0  3  4  5  6  7  8 10 11 13 15 16 17 18 19 20 22 24 26 27 28 29 30 32\n",
      " 33 34 35 36 37 38 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55] [ 1  2  9 12 14 21 23 25 31 39 40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perchDF = > 5등분 (불균형 데이터일때는 Kfold 못씀.)\n",
    "fold_5 = KFold(n_splits=5, shuffle=True)\n",
    "datasets = fold_5.split(perchDF)\n",
    "\n",
    "for idx, (trn, tst) in enumerate(datasets) :\n",
    "    print(f'[{idx}] => {trn} {tst}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 타겟이 분류인 경우\n",
    "irisDF = pd.read_csv('../data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.1\n",
       "1      4.9\n",
       "2      4.7\n",
       "3      4.6\n",
       "4      5.0\n",
       "      ... \n",
       "145    6.7\n",
       "146    6.3\n",
       "147    6.5\n",
       "148    6.2\n",
       "149    5.9\n",
       "Name: sepal.length, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF[irisDF.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=3)\n",
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Setosa\n",
       "2    Setosa\n",
       "3    Setosa\n",
       "Name: variety, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF[irisDF.columns[-1]][[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (trn, tst) in enumerate(ret) :\n",
    "#     print(f'{idx} : {trn} {tst}')\n",
    "#     irisDF[irisDF.columns[:-1]]\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variety\n",
      "Versicolor    0.36\n",
      "Virginica     0.34\n",
      "Setosa        0.30\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Setosa        0.40\n",
      "Virginica     0.32\n",
      "Versicolor    0.28\n",
      "Name: count, dtype: float64\n",
      "==========================================================================================\n",
      "variety\n",
      "Versicolor    0.34\n",
      "Virginica     0.34\n",
      "Setosa        0.32\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Setosa        0.36\n",
      "Versicolor    0.32\n",
      "Virginica     0.32\n",
      "Name: count, dtype: float64\n",
      "==========================================================================================\n",
      "variety\n",
      "Setosa        0.38\n",
      "Virginica     0.32\n",
      "Versicolor    0.30\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Versicolor    0.40\n",
      "Virginica     0.36\n",
      "Setosa        0.24\n",
      "Name: count, dtype: float64\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "trnScore3 = []\n",
    "#for p_name in ['l1', 'l2', 'elasticnet'] :\n",
    "k_fold = KFold(n_splits=3, shuffle=True)\n",
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]])\n",
    "\n",
    "for idx, (trn, tst) in enumerate(ret) :\n",
    "    # 학습용, 테스트용 인덱스 반환\n",
    "    trn_idx = trn.tolist()\n",
    "    tst_idx = tst.tolist()\n",
    "    \n",
    "    # 인덱스에 해당하는 데이터셋 추출\n",
    "    trnDF = irisDF.iloc[trn_idx]\n",
    "    tstDF = irisDF.iloc[tst_idx]\n",
    "    \n",
    "    print(trnDF['variety'].value_counts()/trnDF.shape[0])\n",
    "    print(tstDF['variety'].value_counts()/tstDF.shape[0])\n",
    "    print('='*90)\n",
    "    X_train = trnDF[trnDF.columns[:-1]]\n",
    "    y_train = trnDF[trnDF.columns[-1]]\n",
    "    X_test = tstDF[tstDF.columns[:-1]]\n",
    "    y_test = tstDF[tstDF.columns[-1]]\n",
    "\n",
    "    # 분류 모델 학습\n",
    "    lg_mdl = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "    lg_mdl.fit(X_train, y_train)\n",
    "\n",
    "    # 훈련 및 검증용 성능\n",
    "    trnScore = lg_mdl.score(X_train, y_train)\n",
    "    tstScore = lg_mdl.score(X_test, y_test)\n",
    "    trnScore3.append(trnScore)\n",
    "\n",
    "    # 예측\n",
    "    pre_y = lg_mdl.predict(X_test)\n",
    "    trnScore3.append(trnScore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 발생 코드들... ㅠㅠㅠ\n",
    "   \n",
    "\n",
    " # trnDF = irisDF['variety'][trn_idx]\n",
    "    # tstDF = irisDF['variety'][trn_idx]\n",
    "    # print(trnDF.value_counts())\n",
    "    #print(trnDF['variety'].value_counts()/trnDF.shape[0])\n",
    "    #print(tstDF['variety'].value_counts()/tstDF.shape[0])\n",
    "\n",
    "    # X_train = trnDF[trnDF.columns[:-1]]\n",
    "    # y_train = trnDF[trnDF.columns[-1]]\n",
    "    # X_test = tstDF[tstDF.columns[:-1]]\n",
    "    # y_test = tstDF[tstDF.columns[-1]]\n",
    "\n",
    "    # # 분류 모델 학습\n",
    "    # lg_mdl = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "    # lg_mdl.fit(X_train, y_train)\n",
    "\n",
    "    # # 훈련 및 검증용 성능\n",
    "    # trnScore = lg_mdl.score(X_train, y_train)\n",
    "    # tstScore = lg_mdl.score(X_test, y_test)\n",
    "    # trnScore3.append(trnScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trnScore3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.model_selection.cross_val_score : 점수 평가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
