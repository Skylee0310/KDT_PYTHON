{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader 살펴보기\n",
    "- Pytorch에서 배치크기만 데이터를 조절하기 위한 메커니즘\n",
    "- Dataset : 사용 데이터를 기반으로 사용자 정의 클래스 작성 \n",
    "- DataLoader : 지정된 Datase에서 지정된 배치사이즈 만큼 피쳐와 타겟을 추출하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data => torch.Size([5, 3]) 2D\n",
      "y_data => torch.Size([5, 1]) 2D\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_data = torch.IntTensor([[10, 20, 30],[20, 30, 40],[30, 40, 50],[40, 50, 60], [50, 60, 70]])\n",
    "y_data = torch.IntTensor([[20], [30], [40], [50], [60]])\n",
    "\n",
    "#  행 길이는 꼭 맞춰줘야함!! \n",
    "\n",
    "print(f\"x_data => {x_data.shape} {x_data.ndim}D\")\n",
    "print(f\"y_data => {y_data.shape} {y_data.ndim}D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 TensorDataset 활용 : Dataset의 sub_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorDataset 클래스 로딩\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x21b4a86fee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(x_data, y_data) #(입력데이터, 출력데이터)\n",
    "dataset # 데이터를 쌍으로 묶어서 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 20, 30],\n",
       "         [20, 30, 40],\n",
       "         [30, 40, 50],\n",
       "         [40, 50, 60],\n",
       "         [50, 60, 70]], dtype=torch.int32),\n",
       " tensor([[20],\n",
       "         [30],\n",
       "         [40],\n",
       "         [50],\n",
       "         [60]], dtype=torch.int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-2 사용자 정의 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### data 준비\n",
    "file = '../data/iris.csv'\n",
    "\n",
    "irisDF = pd.read_csv(file)\n",
    "irisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이로도 한번 열어보자\n",
    "irisNP = np.loadtxt(file, delimiter=\",\" ,skiprows=1, usecols=[0, 1, 2, 3])\n",
    "irisNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DataFrame', 'ndarray')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.__class__.__name__, irisNP.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(irisDF, pd.DataFrame), isinstance(irisNP, np.ndarray), isinstance([1, 2], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 DataSet Class\n",
    "# Dataset = 부모 \n",
    "# DLDataset = 자식\n",
    "# 데이터의 텐서변환\n",
    "\n",
    "class DLDataset(Dataset):\n",
    "    # 초기화 함수\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # x, y 데이터 => ndarray\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data \n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data \n",
    "        # 데이터 프레임이라면 values로 arrary 뽑아줘야함 \n",
    "\n",
    "        # ndarray => tensor \n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "\n",
    "    # 데이터셋의 개수 체크 함수\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    # 특정 인덱스 데이터 + 라벨 반환 callback function \n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index] # 둘 다 튜플로 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), 2D\n",
      "targetDF => (150,), 1D\n",
      "targetDF => (150, 1), 2D\n"
     ]
    }
   ],
   "source": [
    "# feature와 label 분리 \n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetNP = irisDF[irisDF.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # object 타입 타겟 => int 타입 타겟 변환 \n",
    "\n",
    "print(f\"featureDF => {featureDF.shape}, {featureDF.ndim}D\")\n",
    "print(f\"targetDF => {targetNP.shape}, {targetNP.ndim}D\")\n",
    "\n",
    "targetNP = LabelEncoder().fit_transform(targetNP).reshape(-1, 1)\n",
    "print(f\"targetDF => {targetNP.shape}, {targetNP.ndim}D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = DLDataset(featureDF, targetNP) # DF, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0])),\n",
       " sepal.length    5.1\n",
       " sepal.width     3.5\n",
       " petal.length    1.4\n",
       " petal.width     0.2\n",
       " Name: 0, dtype: float64,\n",
       " array([0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0], featureDF.iloc[0], targetNP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset2 = DLDataset(irisNP, targetNP) # numpy, numpy # irisNP => 피처만 갖고 온 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-3 학습용, 검증용, 테스트용 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDS => 105개, validDS => 15개, testDS => 30개\n"
     ]
    }
   ],
   "source": [
    "### => 파이토치\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "# 데이터 비율 정하기 \n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS, testDS = random_split(my_dataset2, [0.7, 0.1, 0.2], generator=seed) \n",
    "# 개수로 주던가 비율로 주던가\n",
    "\n",
    "print(f\"trainDS => {len(trainDS)}개, validDS => {len(validDS)}개, testDS => {len(testDS)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 속성 => [42, 95, 30, 64, 52, 35, 130, 40, 82, 17, 108, 94, 68, 97, 117, 127, 41, 44, 57, 140, 149, 32, 23, 102, 16, 113, 71, 18, 67, 66, 0, 25, 101, 112, 91, 3, 59, 116, 86, 84, 106, 142, 43, 39, 26, 98, 93, 20, 87, 19, 120, 114, 7, 63, 76, 89, 36, 45, 37, 56, 58, 122, 51, 145, 24, 21, 105, 62, 15, 11, 48, 133, 88, 50, 6, 134, 111, 8, 49, 75, 69, 124, 4, 147, 80, 100, 99, 141, 47, 107, 13, 109, 129, 28, 38, 53, 121, 5, 55, 31, 73, 74, 54, 29, 12]\n",
      "dataset => <__main__.DLDataset object at 0x0000021B5582C130>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subset 속성 => {trainDS.indices}\\ndataset => {trainDS.dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터 셋 => 학습DS, 테스터DS, 검증DF\n",
    "- 속성 : index가 저장되어 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DataLoader 생성 : 학습용, 검증용, 테스트용\n",
    "# drop_last 매개변수 : 배치사이즈로 데이터셋 분리 후 남는 데이터 처리 방법 설정 (default = False) True하면 걍 버리는 거임(valid로 쓸 데이터 없는 경우 버린 걸 사용하는 경우가 있음 )\n",
    "batch_size = 5\n",
    "trainDL = DataLoader(trainDS, batch_size=batch_size)\n",
    "validDL = DataLoader(validDS, batch_size=batch_size)\n",
    "testDL = DataLoader(testDS, batch_size=batch_size)\n",
    "\n",
    "len(trainDL), len(validDL), len(testDL) \n",
    "# 배치사이즈 만큼 나눠진 수가 나오는 것.\n",
    "# 즉, 1에포크 당 반복을 몇번하는지 알 수 있는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size : 5\n",
      "trainDS => 105개, validDS => 15개, testDS => 30개\n",
      "trainDL => 21개, validDL => 3개, testDL => 6개\n"
     ]
    }
   ],
   "source": [
    "# Epoch당 반복 단위\n",
    "print(f\"Batch_size : {batch_size}\")\n",
    "print(f\"trainDS => {len(trainDS)}개, validDS => {len(validDS)}개, testDS => {len(testDS)}개\")\n",
    "print(f\"trainDL => {len(trainDL)}개, validDL => {len(validDL)}개, testDL => {len(testDL)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] feature torch.Size([5, 4])\n",
      "[1] feature torch.Size([5, 4])\n",
      "[2] feature torch.Size([5, 4])\n",
      "[3] feature torch.Size([5, 4])\n",
      "[4] feature torch.Size([5, 4])\n",
      "[5] feature torch.Size([5, 4])\n",
      "[6] feature torch.Size([5, 4])\n",
      "[7] feature torch.Size([5, 4])\n",
      "[8] feature torch.Size([5, 4])\n",
      "[9] feature torch.Size([5, 4])\n",
      "[10] feature torch.Size([5, 4])\n",
      "[11] feature torch.Size([5, 4])\n",
      "[12] feature torch.Size([5, 4])\n",
      "[13] feature torch.Size([5, 4])\n",
      "[14] feature torch.Size([5, 4])\n",
      "[15] feature torch.Size([5, 4])\n",
      "[16] feature torch.Size([5, 4])\n",
      "[17] feature torch.Size([5, 4])\n",
      "[18] feature torch.Size([5, 4])\n",
      "[19] feature torch.Size([5, 4])\n",
      "[20] feature torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "for _, (feature, target) in enumerate(trainDL):\n",
    "    print(f\"[{_}] feature {feature.shape}\")\n",
    "    ## 로더에서 가지고 온 데이터 만큼 학습 진행 \n",
    "    ## 학습 후에는 검증도 할 것! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Model 클래스 정의 : 입출력 feature 수, 층 수, 은닉층의 노드 수 \n",
    "    * 입력층 : 입력 <= 피쳐 개수, iris 4개\n",
    "    * 은닉층 : 마음대로 알아서 잘 \n",
    "    * 출력층 : 출력 <= 분류 = 타겟 클래스 수만큼 / 회귀 = 무조건 1개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # linear Regression 기능의 클래스 Linear\n",
    "import torch.nn.functional as F # 손실함수\n",
    "import torch.optim as optim # 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CModel(nn.Module):\n",
    "    # 구성요소 정의 함수\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_dim, 100) # in_dim ==> 컬럼 수.\n",
    "        self.relu = nn.ReLU() # 활성화 함수 \n",
    "        self.hidden_layer = nn.Linear(100, 27)\n",
    "        self.output_layer = nn.Linear(27, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 학습 준비 : 실행디바이스, 모델, 최적화, 손실함수, 학습 횟수, 학습 함수, 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 설정\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPU있으면 쓰고 없으면 cpu로 \n",
    "\n",
    "# 학습 횟수\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스\n",
    "IN, OUT = my_dataset2.feature.shape[1], len(my_dataset2.target.unique()) # in은 피처의 컬럼 수/ out은 target의 고유값 수\n",
    "model = CModel(IN, OUT).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset2.feature.shape[1], len(my_dataset2.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 인스턴스 \n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE) # 다중분류니까\n",
    "\n",
    "# 최적화 인스턴스\n",
    "OPTIMIZER = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
