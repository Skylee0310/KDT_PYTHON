{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from model import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 1696), (7954, 1))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv로 만든 파일 불러오기.\n",
    "df = pd.read_csv('encoded.csv', index_col=0) # 0번째 열을 인덱스로 지정.\n",
    "vocaDF = pd.read_csv('vocab.csv', index_col=0)\n",
    "df.shape, vocaDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0'], dtype='object')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocaDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model.pth'\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "EMBEDD_DIM  = 128\n",
    "VOCAB_SIZE  = vocaDF.shape[0]\n",
    "NUM_LAYERS = 1\n",
    "EPOCHS      = 100\n",
    "LR          = 0.1\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT     = 0.5\n",
    "OUTPUT      = 8\n",
    "\n",
    "mdl = LSTM(VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor((text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = torch.tensor([0]).to(device)\n",
    "        predicted_label = model(text)\n",
    "        result = predicted_label.argmax(1).item()\n",
    "        if result == 0: genre='ballad'\n",
    "        elif result == 1 : genre='dance'\n",
    "        elif result == 2 : genre='fork'\n",
    "        elif result == 3 : genre='hiphop'\n",
    "        elif result == 4 : genre='indi'\n",
    "        elif result == 5 : genre='R&B'\n",
    "        elif result == 6 : genre='rock'\n",
    "        elif result == 7 : genre='trot'\n",
    "        return genre\n",
    "    \n",
    "# def predict(model, text, text_pipeline):\n",
    "#     with torch.no_grad():\n",
    "#         text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "#         text = text.unsqueeze(0)\n",
    "#         offsets = torch.tensor([0]).to(device)\n",
    "#         predicted_label = model(text, offsets)\n",
    "#         return predicted_label.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '아름다운 청춘의 한 장 함께 써내려 가자 너와의 추억들로 가득 채울래 (come on!) 아무 걱정도 하지는 마, 나에게 다 맡겨 봐 지금 이 순간이 다시 넘겨볼 수 있는 한 페이지가 될 수 있게.'\n",
    "#text = '월요일엔 아마 바쁘지 않을까 화요일도 성급해 보이지 안 그래 수요일은 뭔가 어정쩡한 느낌 목요일은 그냥 내가 왠지 싫어'\n",
    "#text = '다 너의 반 반 반의 반의 반도 채워주질 못 하네 채워지지가 않네 Yeah 딱 너의 반 반 반의 반이라도 내게 남았더라면 이렇게 붕 떠있진 않을 텐데'\n",
    "#text = '모두 할 말을 잃지 Like you 4차원 이상의 기적의 View 달콤히 찍어 문 빛의 퐁듀 보이기 시작한 음의 색도 예민해진 걸 느껴 뚜렷한 색감과 여섯 번째 감각'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokentext(text, vocaDF) :\n",
    "\n",
    "    from konlpy.tag import Kkma\n",
    "    kkma = Kkma()\n",
    "    texttoken = kkma.morphs(text)\n",
    "\n",
    "    # 어휘사전\n",
    "    vocab_dict = {word: idx for idx, word in enumerate(vocaDF['0'].to_list())}\n",
    "    encoded = [vocab_dict[token] for token in texttoken if token in vocab_dict]\n",
    "    # 인코딩 결과 출력\n",
    "    print(\"토큰화된 단어들:\", texttoken)\n",
    "    print(\"인코딩 결과:\", encoded)\n",
    "    padded_id=[]\n",
    "    max_length = df.shape[1]\n",
    "\n",
    "    if len(encoded) < max_length :\n",
    "        padded_id.append(encoded + [0]*(max_length-len(encoded)))\n",
    "    else :\n",
    "        padded_id.append(encoded)\n",
    "    return padded_id[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 단어들: ['아름답', 'ㄴ', '청춘', '의', '한', '장', '함께', '써내', '려', '가', '자', '너와', '의', '추억', '들', '로', '가득', '채우', 'ㄹ래', '(', 'come', 'on', '!', ')', '아무', '걱정', '도', '하지', '는', '마', ',', '나', '에게', '다', '맡기', '어', '보', '아', '지금', '이', '순간', '이', '다시', '넘겨보', 'ㄹ', '수', '있', '는', '한', '페이지', '가', '되', 'ㄹ', '수', '있', '게', '.']\n",
      "인코딩 결과: [169, 784, 40, 99, 107, 197, 60, 111, 96, 282, 2130, 623, 26, 38, 7, 2530]\n"
     ]
    }
   ],
   "source": [
    "token = tokentext(text, vocaDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance\n"
     ]
    }
   ],
   "source": [
    "genre = predict(mdl, token) #[0: 'ballad', 1:'dance', 2: 'fork', 3:'hiphop', 4:'indi', 5:'R&B', 6:'rock', 7:'trot']\n",
    "print(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
